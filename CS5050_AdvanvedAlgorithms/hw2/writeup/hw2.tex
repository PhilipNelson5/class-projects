\documentclass[11pt]{article}

\usepackage{latexsym}
%\newcommand{\epsfig}{\psfig}
\usepackage{tabularx,booktabs,multirow,delarray,array}
\usepackage{graphicx,amssymb,amsmath,amssymb,mathrsfs}
%\usepackage{hyperref}
\usepackage[linesnumbered, vlined, ruled]{algorithm2e}
\usepackage{listings}

%\usepackage[T1]{fontenc}

\aboverulesep=0pt
\belowrulesep=0pt

%\marginparwidth=0in
%\marginparsep=0in
\oddsidemargin=0.0in
\evensidemargin=0.0in
\headheight=0.0in
%\headsep=0in
\topmargin=-0.40in %0.35
\textheight=9.0in %9.1in
\textwidth=6.5in   %6.55in

\usepackage{fullpage}

\begin{document}
\baselineskip=14.0pt

\title{CS5050 \textsc{Advanced Algorithms}
\\{\Large Spring Semester, 2018}
\\ Assignment 2: Divide and Conquer
\\{\Large {\bf Philip Nelson}: worked with Raul Ramirez, Ammon Hepworth}
\\ {\large {\bf Due Date: 3:00 p.m.}, Thursday, Feb. 8, 2018 ({\bf at the beginning of CS5050 class})}}
\date{}
%\date{\today}

\maketitle
%\theoremstyle{plain}\newtheorem{theorem}{\textbf{Theorem}}

\vspace{-0.9in}

\begin{enumerate}
\item % question 1
Let $A[1\cdots n]$ be an array of $n$ {\em distinct} numbers (i.e., no two
numbers are equal). If $i<j$ and $A[i]>A[j]$, then the pair
$(A[i],A[j])$ is called an {\em inversion} of $A$.

\begin{enumerate}
\item % a
  All of the inversions are: $\{(4,2),(4,1),(2,1),(9,1),(9,7)\}$

\item % b
  What array with elements from the set $\{1,2,\ldots,n\}$ has the most inversions?
  \begin{itemize}
    \item The array $\{n,\ldots,2,1\}$ has the most inversions.
    \item It would have $\frac{n(n-1)}{2}$ inversions.
  \end{itemize}

\item % c
  Give a divide-and-conquer algorithm that computes the number of
  inversions in array $A$ in $O(n\log n)$ time.
\begin{description}
\item[1. Algorithm Description]

  The \textit{count\_inversions} algorithm counts the number of inversions of the array $A$ in $O(n\log{n})$ making use of a divide and conquer technique similar to merge sort. The divide step is exactly the same as merge sort. Each time the \textit{mid} is calculated and the functions is recursively called from \textit{start} to \textit{mid} and \textit{mid+1} to \textit{end}. The inversions are counted during the combine step. When $A[i] < A[j] \wedge i > j$, an inversion is counted. However, since the array is being sorted, we can take advantage of the sorted property. If $A[i] < A[j] \wedge i > j$ then all the elements, $\{A[i], A[i+1], \cdots, A[mid]\}$ are also inversions; that is $(mid - i + 1)$ inverisons. Therefore each time we encounter the situation $A[i] < A[j] \wedge i > j$, we add $mid - i + 1$ to the inversion count. This allows the combine phase to complete in $O(n)$ time.


\item[2. Pseudocode]
fill\_knapsack

\begin{lstlisting}[language=C++,
                   % directivestyle={\color{black}}
                   % emph={int,char,double,float,unsigned},
                   % emphstyle={\color{blue}}
                  ]
int mergeList(std::vector<int>& A, int start, int mid, int end)
{
  int inversions = 0;
  std::vector<int> merged;
  int i = start;
  int j = mid + 1;

  while (i <= mid && j <= end)
  {
    if (A[i] < A[j])
      merged.push_back(A[i++]);
    else
    {
      if (i < j)
        inversions += mid - i + 1;

      merged.push_back(A[j++]);
    }
  }

  while (i <= mid)
    merged.push_back(A[i++]);

  while (j <= end)
    merged.push_back(A[j++]);

  for (unsigned int x = start, y = 0; y < merged.size(); ++x, ++y)
    A[x] = merged[y];

  return inversions;
}

int mergeSort(std::vector<int>& A, int start, int end)
{
  if (end - start == 0)
    return 0;

  auto mid = (start + end) / 2;

  return mergeSort(A, start, mid) +
    mergeSort(A, mid + 1, end) +
    mergeList(A, start, mid, end);
}
\end{lstlisting}

\item[3. Correctness]

  The first way to fill the knapsack is obviously correct. The algorithm will put any single element $a_i : \frac{K}{2} \leq a_i \leq K$ in the knapsack. If no such single element exists, the knapsack will be filled with elements $a_j : a_j < \frac{K}{2}$. It is impossibe to overfill the knapsack using this method. If two elements $a_1$ and $a_2$ are put in the knapsack such that $a_1, a_2 < \frac{K}{2}$, the elements will be $\frac{k-1}{2}$ at the largest. Thus

  \[a_1 + a_2 = \frac{K-1}{2}+\frac{K-1}{2}=\frac{2K-2}{2}=K-1\]

  Therefore any $a_1 + a_2$, where $a_1$ and $a_2$ could be combinations of multiple $a_j$, will never be more than $K-1$ therefore a solution will always be found.

\item[4. Time Analysis]
Please make sure that you analyze the running time of your algorithm.

The algorithm \textit{fill\_knapsack} solves the knapsack problem, factor two approximation, in order $O(n)$. The order is $O(n)$ because there is one for loop which does a linear scan over the array $A$ containing $n$ elements. During the linear scan, a constant amount of work is done; this only affects the order by a constant ammount and therefore can be ignored. Thus, \textit{fill\_knapsack} is $O(n)$.

\end{description}

\end{enumerate}

\item % question 2

Let $A[1\ldots a]$ be an array of $a$ elements and $B[1\ldots b]$ another array of $b$ elements, with $b\leq a$. Note that neither $A$ nor $B$ is sorted. The problem is to compute the number of elements of $A$ that are smaller than $B[i]$ for each element $B[i]$ with $1\leq i\leq m$.
For simplicity, we assume that no two elements of $A$ are equal and no two elements of $B$ are equal.

For example, let $A$ be $\{30, 20, 100, 60, 90, 10, 40, 50, 80, 70\}$ of ten elements. Let $B$ be $\{60, 35, 73\}$ of three elements. Then, your answer should be the following: for 60, return 5 (because there 5 numbers in $A$ smaller than 60); for 35, return 3; for 73, return 7.

\begin{enumerate}
\item
Design an $O(a\log a)$ time algorithm for solving the problem. {\hfill \bf (5 points)}

\item
Design an $O(ab)$ time algorithm for the problem. Note that this is better than the $O(a\log a)$ time algorithm if $b<\log a$. {\hfill \bf (5 points)}

\item
Improve your algorithm to $O(a\log b)$ time. Because $b\leq a$, this is better than both the $O(a\log a)$ time and the $O(ab)$ time algorithms. {\hfill \bf (20 points)}


{\bf Hint:} Use the divide and conquer technique. Since $b\leq a$, you cannot sort the array $A$ because that would take $O(a\log a)$ time, which is not $O(a\log b)$ as $b$ may be much smaller than $n$.
\end{enumerate}


{\bf Note:}
You will receive the full 30 points if you give an $O(a\log b)$ time algorithm directly for (c) without giving any algorithms for (a) or (b).


\item % question 3
{\bf (20 points)}
Solve the following recurrences (you may use any of the methods we studied in class). Make your bounds as small as possible (in the big-$O$ notation). For each recurrence, $T(n)$ is constant for $n\leq 2$.

\begin{enumerate}

\item
$T(n)=2\cdot T(\frac{n}{2})+ n^3$.

$a=2,\ b=2,\ f(n)=n^3$

$n^3 = n^{\log_2{2}}$


case 3:
\begin{enumerate}

  \item
    $n^3 = \Omega(n^{1+\epsilon}),\ \epsilon > 2$

  \item
    $2\cdot\left(\frac{n}{2}\right)^3 \leq cn^3\Rightarrow \frac{1}{4}n^3\leq cn^3 ,\ \frac{1}{4}\leq c < 1 $

\end{enumerate}

\[\boxed{T(n) = \Theta\left(n^3 \right)}\]

\item
$T(n)=4\cdot T(\frac{n}{2})+n\sqrt{n}$.

$a=4,\ b=2,\ f(n)=n^{\frac{3}{2}}$

$n^{\frac{3}{2}} = n^{\log_2 4}$

case 1:

$n^{\frac{3}{2}} = O\left(n^{\frac{4}{2}-\epsilon}\right),\ 0 < \epsilon < \frac{1}{2}$

\[\boxed{T(n) = \Theta\left(n^2 \right)}\]


\item
$T(n)=2\cdot T(\frac{n}{2})+n\log n$.

$a=2,\ b=2,\ f(n)=n\log n$

$n\log n = \Theta(n^{\log_2 2} log^k n)$

If $f(n)=\Theta (n^{\log_{b}a}\log^{k}n),\ k \geq 0 \Rightarrow T(n)=\Theta (n^{\log_{b}a}\log^{k+1}n)$

$n\log n = \Theta(n^{\log_2 2} log^k n),\ k=1$

\[\boxed{T(n)=n\log^2 n}\]



% $T(\frac{n}{2}) = 2 \cdot T(\frac{n}{4})+\frac{n}{2}\log\frac{n}{2}$
%
% $T(n)=2\cdot (2 \cdot T(\frac{n}{4})+\frac{n}{2}\log\frac{n}{2})+n\log n$.
%
% $T_k(n)=2^k \cdot T(\frac{n}{2^k})+kn\log\left(\frac{n}{2^{k-1}}\right)+n\log n$.
%
% $T_k(n)=2^k \cdot T(\frac{n}{2^k})+kn(\log n - k + 1)+n\log n$.
%
% $T_k(n)=2^k \cdot T(\frac{n}{2^k})+kn\log n - k^2n + kn+n\log n$.
%
% $let\ k = \log n$
%
% $T_{\log n}(n) = n \cdot 1 + n\log^2 n -\log^2 n + n\log n + n\log n$
%
% $T_{\log n}(n) = n + 2n\log n$
%
% \[\boxed{T(n) = O(n\log n)}\]

\item
$T(n)=T(\frac{3}{4}\cdot n)+n$.



\end{enumerate}

\item % question 4
 {\bf (20 points)}
You are consulting for a small computation-intensive investment company, and
they have the following type of problem that they want to solve over and over.
A typical instance of the problem is the following. They are doing a simulation
in which they look at $n$ consecutive days of a given stock, at some point in the past.
Let's number the days $i=1,2,\ldots,n$; for each day $i$, they have a price $p(i)$ per share for the stock on that day. (We'll assume for simplicity that the price was fixed during each day.) Suppose during this time period, they wanted to buy 1000 shares on some day and sell all these shares on some (later) day. They want to know: When should they have bought and when should they have sold in order to have made as much money as possible? (If there was no way to make money during the $n$ days, you should report this instead.)

For example, suppose $n=5$, $p(1)=9$, $p(2)=1$, $p(3)=5$, $p(4)=4$, $p(5)=7$. Then you should return ``buy on $2$, sell on $5$'' (buying on day $2$ and selling on day $5$ means they would have made \$6 per share, the maximum possible for that period).

Clearly, there is a simple algorithm that takes time $O(n^2)$: try all possible pairs of buy/sell days and see which makes them the most money. Your investment friends were hoping for something a little better.

Design an algorithm to solve the problem in $O(n\log n)$ time. Your algorithm should use the divide-and-conquer technique.


{\bf Note:} The divide-and-conquer technique can actually solve the problem in $O(n)$ time. But such an algorithm is not required for this assignment. You may think about it if you would like to challenge yourself.
\end{enumerate}

\end{document}

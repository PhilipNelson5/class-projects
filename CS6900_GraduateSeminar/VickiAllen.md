---
title: 'Dr. Vicki Allen'
author: Philip Nelson
date: 13 November 2019
---

Dr. Vicki Allen's major research areas are multi agent systems.

Dr. Vicki Allen's research group has been working on the following projects:

* Ride sharing algorithms
* Traffic algorithms for smart city
* Genetic algorithms for traveling salesman

I liked the interesting questions posed by Dr. Allen about voting and auctioning. Her research into multi agent systems seemed interesting too. It is interesting to think about how independent agents make decisions without perfect knowledge of a system.

Two researchers in the filed of multi agent systems are Dr. Sarvapali D. (Gopal) Ramchurn at University of Southampton and Dr. Trung Dong Huynh at King's College London.

Dr. Sarvapali Ramchurn published a paper entitled "Argumentation-based negotiation" [https://pure.mpg.de/rest/items/item_3020491/component/file_3036210/content](https://pure.mpg.de/rest/items/item_3020491/component/file_3036210/content). In this paper, Dr. Ramchurn discusses argumentation-based negotiation in mulit-agent systems.He says that in multi agent systems, negotiation is essential in settings where autonomous agents have conflicting interests and a desire to cooperate. For this reason, mechanisms in which agents exchange potential agreements according to various rules of interaction have become very popular in recent years as evident. However, as research continues, it is now becoming more obvious the limitations in such mechanisms and Dr. Ramchurn advocates the idea that agents can increase the likelihood and quality of an agreement by exchanging arguments which influence each others’ states. He further argues that argument exchange is sometimes essential when various assumptions about agent rationality cannot be satisfied. In this article, he identifies the main research motivations and ambitions behind work in the field. He then provide a conceptual framework through which we outline the core elements and features required by agents engaged in argumentation-based negotiation, as well as the environment that hosts these agents. For each of these elements, they survey and evaluate existing proposed techniques in the literature and highlight the major challenges that need to be addressed if argument-based negotiation research is to reach its full potential.

Dr. Sarvapali Ramchurn published a paper entitled "Trust in multi-agent systems" [https://www.cambridge.org/core/services/aop-cambridge-core/content/view/C5B2F5A2B8D66354CB04F2148BF144F2/S0269888904000116a.pdf/trust_in_multiagent_systems.pdf](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/C5B2F5A2B8D66354CB04F2148BF144F2/S0269888904000116a.pdf/trust_in_multiagent_systems.pdf). In this paper, Dr. Ramchurn discusses trust in multi-agent systems. He statues that trust is a fundamental concern in large-scale open distributed systems. It lies at the core of all interactions between the entities that have to operate in such uncertain and constantly changing environments. Given this complexity, Dr. Ramchurn says that these components, and the ensuing system, are increasingly being conceptualised, designed, and built using agent-based techniques and this paper examines the specific role of trust in multi-agent systems. In particular, Dr. Ramchurn surveys the state of the art multi-agent system techniques and provides an account of the main directions along which research efforts are being focused. In so doing, he evaluates the relative strengths and weaknesses of the main models that have been proposed and show how they all seek to fundamentally minimize the uncertainty in interactions. Finally, he outlines the areas that require further research in order to develop a comprehensive treatment of trust in complex computational setting.

Dr. Trung Huynh published a paper entitled "Certified Reputation: How an Agent Can Trust a Stranger" [https://eprints.soton.ac.uk/262587/1/dong.aamas06.pdf](https://eprints.soton.ac.uk/262587/1/dong.aamas06.pdf). In this paper, Dr. Huynh discusses certified reputation, or how an agent can trust a stranger. Current computational trust models are usually built either on an agent's direct experience of an interaction partner, called interaction trust, or reports provided by third parties about their experiences with a partner, called witness reputation. However, Dr. Huynh says that both of these approaches have their limitations. Models using direct experience often result in poor performance until an agent has had a sufficient number of interactions to build up a reliable picture of a particular partner and witness reports rely on self-interested agents being willing to freely share their experience. To this end, in this paper, Dr. Huynh presents Certified Reputation (CR), a new model of trust that can overcome these limitations. Specifically, CR works by allowing agents to actively provide third-party references about their previous performance as a means of building up the trust in them of their potential interaction partners. By so doing, trust relationships can quickly be established with much lower cost to the involved parties. He empirically evaluate CR and show that it helps agents pick better interaction partners more quickly than models that do not incorporate this form of trust.

Dr. Trung Huynh published a paper entitled "Human–agent collaboration for disaster response" [https://link.springer.com/article/10.1007/s10458-015-9286-4](https://link.springer.com/article/10.1007/s10458-015-9286-4). In this paper, Dr. Huynh discusses human agent collaboration for disaster response. In the aftermath of major disasters, first responders are typically overwhelmed with large numbers of spatially distributed search and rescue tasks. Each task with it's own requirements. Additionally, responders have to operate in highly uncertain and dynamic environments where new tasks may appear and hazards may be spreading across the disaster space. Hence, rescue missions may need to be re-planned as new information comes in, tasks are completed, or new hazards are discovered. Finding an optimal allocation of resources to complete all the tasks is a major computational challenge. In this paper Dr. Huynh uses decision theoretic techniques to solve the task allocation problem posed by emergency response planning and then deploys thier solution as part of an agent-based planning tool in real-world field trials. He is able to study the interactional issues that arise when humans are guided by an agent. Specifically, He develops an algorithm based on a multi-agent Markov decision process representation of the task allocation problem and shows that it outperforms standard baseline solutions. We then integrates the algorithm into a planning agent that responds to requests for tasks from participants in a mixed-reality location-based game, called AtomicOrchid. The game simulates disaster response settings in the real-world. He then ran a number of trials of their planning agent and compared it against a purely human driven system. Dr. Huynh's analysis of these trials showed that human commanders adapt to the planning agent by taking on a more supervisory role and that by providing humans with the flexibility of requesting plans from the agent, it allowed them to perform more tasks more efficiently than using purely human interactions to allocate tasks. He also discussed how improved flexibility could lead to worse performance if left unchecked.

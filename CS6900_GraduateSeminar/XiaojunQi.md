---
title: 'Dr. Xiaojun Qi'
author: Philip Nelson
date: 4th September 2019
---

Dr. Qi's major research areas are computer vision, pattern recognition, image processing and deep learning. The focus of her recent projects is using machine learning to solve problems in computer vision.

Her research group is or has been working on the following projects:

* Facial Recognition Under Varying Illumination

* Object Recognition in Video Using Deep Learning

* Object Recognition

* Visual Tracking

* Identifying Highway Features on LIDAR Imagery

Two researchers in the filed of computer vision are Dr. Shih-Fu Chang at Columbia University and Dr. William T. Freeman at MIT.

Dr. Chang recently published a paper entitled "Urban Semantic 3D Reconstruction from Multiview Satellite Imagery" [http://openaccess.thecvf.com/content_CVPRW_2019/papers/EarthVision/Leotta_Urban_Semantic_3D_Reconstruction_From_Multiview_Satellite_Imagery_CVPRW_2019_paper.pdf](http://openaccess.thecvf.com/content_CVPRW_2019/papers/EarthVision/Leotta_Urban_Semantic_3D_Reconstruction_From_Multiview_Satellite_Imagery_CVPRW_2019_paper.pdf). In this paper, Dr. Chang explores a solution to the problem of automated 3D urban modeling. An issue that his new approach addresses is a "melted" appearance which current methods produce. This occurs at sharp corners and where buildings intersect with the surrounding terrain. I found this paper interesting because I have noticed this flaw in Google Maps. Their method uses a combination of traditional image processing in conjunction with deep neural networks to produce some great results.

Dr. Chang also recently published another paper entitled "Detecting and Simulating Artifacts in GAN Fake Images" [Detecting and Simulating Artifacts in GAN Fake Images](Detecting and Simulating Artifacts in GAN Fake Images). I found this topic interesting because I have discussed the implications of GAN and DeepFakes in future legal cases. It is important to see that there is successful research into detecting these kinds of constructed images. This paper helped solve the problem of detecting GAN images by removing the necessity to have known real and fake images from the targeted GAN network. These are often difficult or impossible to obtain. The researchers were able to generate training data without access to the target GAN network. This research takes us one step closer to being able to reliably distinguish what is real from what is fake.

Dr. Freeman recently authored a paper entitled "Learning the Depths of Moving People by Watching Frozen People" [http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Learning_the_Depths_of_Moving_People_by_Watching_Frozen_People_CVPR_2019_paper.pdf](http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Learning_the_Depths_of_Moving_People_by_Watching_Frozen_People_CVPR_2019_paper.pdf). This paper explores a new solution to the problem of creating depth maps of a video. Depth maps are useful for adding special effects to videos in post production. Their solution trained a deep neural network on videos of the "MannequinChallenge", a collection of videos of people imitating mannequins, (freezing in different, poses, while a camera moves around the scene). Because people are stationary, they are able to take advantage of the parallax  effect where things in the background move more that things in the foreground.

Dr. Freeman also recently authored a paper entitled "Looking to Listen at the Cocktail Party: A Speaker-Independent Audio-Visual Model for Speech Separation" [https://arxiv.org/pdf/1804.03619.pdf?fbclid=IwAR1N8iGGwd_A7kdSm0h2K7UO0j-QaqUA4oZJZlvboHn5pjCbQ1oJH-lS6eA](https://arxiv.org/pdf/1804.03619.pdf?fbclid=IwAR1N8iGGwd_A7kdSm0h2K7UO0j-QaqUA4oZJZlvboHn5pjCbQ1oJH-lS6eA). This paper attempts to solve the problem of speech separation with background noise. The novelty of the approach is to use both audio and visual information to separate the voices. I liked this approach because it is able to solve the problem more effectively than audio only approaches as well as providing more information in the solution in the form of the video and the ability to visually show who is talking. I also appreciate how Dr. Freeman's papers are given an interesting and less technical title as well as a technical one. In this paper, "Looking to Listen at the Cocktail Party" catches my attention and is intriguing. Then, "A Speaker-Independent Audio-Visual Model for Speech Separation" gives some insight into the methods discussed in the paper. These kinds of titles make the paper more approachable, especially by those who are not field experts.

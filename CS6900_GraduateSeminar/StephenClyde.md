---
title: 'Dr. Stephen Clyde'
author: Philip Nelson
date: 9th September 2019
---

Dr. Stephen Clyde's major research areas are software engineering and distributed systems. Although he has studied these two fields individually, Dr. Clyde finds the research at their intersection the most interesting.

Dr. Stephen Clyde's research group has been working on the following projects:

* Abstraction, modularity, and encapsulation in multi-paradigm software development
* Development frameworks for distributed systems (INGRIM)
* Child-health advanced record management (CHARM)
* High-level aspects
* Testing distributed systems
* Test-case generation and extraction

I liked the INGRIM project, it was the only project Dr. Clyde described in much detail but it was very exciting. Dr. Clyde and his students have been developing a distributed, decentralized mesh network for use off line through a protocol called wifi-direct. The goal of INGRIM is to allow for the straightforward development of apps that can take advantage of the compute power of many mobile devices in an off line scenario. Apps build on INGRIM could be used to coordinate fire fighters or disaster relief workers. I thought this project was exciting and has huge potential for helping the world.

Two researchers in the filed of distributed systems are Dr. Manos Kapritsos at University of Michigan and Dr. Weverton Cordeiro at 	Universidade Federal do Rio Grande do Sul.

Dr. Manos Kapritsos published a paper entitled "Towards Automatic Inference of Inductive Invariants" [https://dl.acm.org/citation.cfm?id=3321451](https://dl.acm.org/citation.cfm?id=3321451). In this paper, Dr. Kapritsos discusses the difficulty of designing and implementing distributed systems. Format verification can provide correctness through proofs. It has been successfully applied to various distributed systems. In order to construct a verification proof, a computer checks an inductive variant. Coming up with this inductive variant is the hardest part so Dr. Kapritsos et al. have come up with a new approach called Incremental Inference of Inductive Invariants, I4, to automatically generate inductive invariants for distributed protocols. Starting with the simple idea "the inductive invariant of a finite instance of the protocol must be an instance of a general inductive invariant for the infinite distributed protocol", Dr. Kapritsos in I4 instantiates a finite instance of the protocol. Then I4 works out the finite inductive invariant of this instance. Finally figure out the general inductive invariant as a generalization of the finite invariant. Their experiments have shown that I4 can finish the general proof of correctness of several systems with minimal human effort.

Dr. Manos Kapritsos published a paper entitled "IronFleet: proving practical distributed systems correct" [https://dl.acm.org/citation.cfm?id=2815428](https://dl.acm.org/citation.cfm?id=2815429). In this paper, Dr. Kapritsos describes a solution to the notorious problems in distribute systems harboring sublet bugs. In theory these problems can be eliminated through verification. However this verification has historically been difficult to apply to full scale distributed systems. In this paper, Dr. Kapritsos describes a methodlogy for building practical and provably correct distributed systems which is based on a unique blend of TLA style state machine refinement and Hoare logic verification. Dr. Kapritsos et al. demonstrate the methodology on a complex implementatoin of a Paxos bbased replicated state machine library and a lease based shared key-value store. They prove that each system obyes a concise safety specification as well as desirable liveness requirements. With their methodology, they are raising the standard for distributed systems from simply being tested, to being correct.

Dr. Weverton Cordeiro published a paper entitled "Don't lose sleep over availability: the GreenUp decentralized wakeup service" [https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final79.pdf](https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final79.pdf). In this paper, Dr. Weverton tackles a problem faced by large companies and organizations with their computer networks. A large amount power, and therefore money, can be saved if idle computers can be put to sleep. Current systems in place let desktops sleep and wake on demand but often, IT departments don't want to deploy these systems because they require special hardware, virtualization technology, or dedicated proxies. None of these requirements are cost effective. In response to this problem, Dr. Weverton details in this paper a software only system called GreenUp. GreenUp allows any machine to act as a proxy for other sleeping machines in its subnet. In order to achieve this solution, GreenUp uses novel distributed techniques that spread the load. It randomly and efficiently synchronizes the state within a subnet and maintains a minimal number of active proxies to coordinate sleep times. GreenUp has been run on a system of over 100 machines and at the time of the paper a trial with approximately 1,100 machines in progress.


Dr. Weverton Cordeiro published a paper entitled "Funnel: Choking Polluters in BitTorrent File Sharing Communities" [https://ieeexplore.ieee.org/document/6070519](https://ieeexplore.ieee.org/document/6070519). BitTorrent based file shareing communities are a very popular form of peer-to-peer (P2P) file sharing which is used to distribute many forms of data over a network, usually the Internet. This massive distributed system of file sharing was reportedly responsible for 3.35% of all bandwidth used world wide. Complaints from the community hint that such BitTorrent and other sharing communities are exposed to "content pollution" attacks where publication of "false" files, viruses, or other malware require a moderation effort from their administrators. Due to the enormous size of such a task which only increases with content publishing rate, it becomes infeasible to do manually. To tackle this problem, Dr. Weverton proposes a generic "pollution control strategy". He and his team instantiate it as a mechanism for BitTorrent communities to control pollution amongst their community. The strategy follows a conservative approach: it regards newly published content as polluted, and allows the dissemination rate to increase according to the proportion of positive feedback issued about the content from downloaders. In contrast to previous solutions, the strategy avoids the problem of pollution dissemination at the initial stages, when insufficient feedback is available, to form a reputation about the content. To evaluate their proposed solution, Dr. Weverton et al. conducted a set of experiments using a popular BitTorrent agent. Their results indicate that the proposed approach mitigates the dissemination of polluted content in BitTorrent, imposing a low overhead in the distribution of non-polluted ones.
